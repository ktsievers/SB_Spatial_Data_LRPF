{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Housekeeping:  \n",
    "This is code using python code for ArcGIS using the specific arcpy packages    \n",
    "  \n",
    "If running in the notebook function within the ArcGIS software, you dont need to do anything special.   \n",
    "  \n",
    "If you would like to run in Visual Studio Code:  \n",
    "Press Control + Shift + P and search for “>Python: Select Interpreter”.  \n",
    "The command palette will drop down, and you should see some options to seelct. Choose the first option when it says, “Enter interpreter path…”:  \n",
    "TO find your interpreter path in its default location go to the following path or select the following path in the dropdown menu:  \n",
    "    C:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\  \n",
    "  \n",
    "further instructions here: https://resources.esri.ca/getting-technical/how-to-configure-visual-studio-code-with-arcgis-pro-s-python-environment  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Code Sections  \n",
    "note - code section links wont work if this cell and the linked cell are not rendered (Cntrl+Enter or Shift+Enter) will render them.  \n",
    "*There are sections that you will need to go and edit or configure based on your computer and spatial requirements - see chunk below this*      \n",
    "\n",
    "[Set Workspaces](#workspace)  \n",
    "[Layers Required](#layersrequired)  \n",
    "[Layers Created](#layerscreated)  \n",
    "  \n",
    "[1. Editing Needed](#editing)    \n",
    "   > [Setting File Names](#filenames)   \n",
    "   > [Setting Specific Parameters](#parameters)  \n",
    "       > Distance to Coast\n",
    "       > Reef Classifications  \n",
    "       > Projected Coordinate System  \n",
    "       > Geographic Coordinate System        \n",
    "      \n",
    "[2. Manipulating Downloaded Data](#manipulations)  \n",
    "   > [Moving layers to gdb folder](#movelayers)  \n",
    "   > [Allen Atlas Data Management](#reefhab_convert)   \n",
    "   > [Getting Mangrove Habitat](#mangrove)\n",
    "   > [Cleaning Population Data](#popconvert)  \n",
    "   > [Cleaning Sediment Layer](#sed_clean)  \n",
    "   > [Setting Coordinate Systems](#coordinates)  \n",
    "   > [Generating Blank Rasters](#blankrasters)   \n",
    "   \n",
    "     \n",
    "[3. Generate Reef Layer](#ReefLayer)    \n",
    "   >  [3a. Geomorphic + benthic](#allen)  \n",
    "   >  [3b. Adjacent Reef](#adj_reef)  \n",
    "   >  [3c. Combine Reef, Adjacent Areas, Mangroves](#combinereeflayers)  \n",
    "   >  [3d. Scale Reef Later](#scalereef)  \n",
    "      \n",
    "[4. Generate Access Layer](#access)  \n",
    "   >  [4a. Distance from coast](#distcoast)  \n",
    "   >  [4b. Population estimate to coast](#popcoast)  \n",
    "   >  [4c. Distance to City](#dist_city)  \n",
    "   >  [4c. Combine Access Layers](#combineaccess)  \n",
    "      \n",
    "[5. Modify Sediment Layer](#sediment)\n",
    "   >  [5a. Scale Sed Layer](#scale_sed)  \n",
    "   > this layer isnt explicitly included, but when/if we decide to add sedimentation, its here.\n",
    "\n",
    "[6. Combine \"Impact\" Layers](#combine_impact)\n",
    "   >  [6a. combine, dist, pop, and sediment]\n",
    "   \n",
    "  \n",
    "[7. Combining Reef Area + Access](#impact)    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Sections you *MUST* EDIT   \n",
    "or at least check to make sure they are correct  \n",
    "[Set New Geodatabase Folder](#new_gdb)  (only do on the first time running this code)  \n",
    "[Set Folder Location for Raw Data](#raw_data)  \n",
    "[Set Workspaces](#workspaces)  \n",
    "[Setting Layer Names](#filenames)   \n",
    "[Setting Parameter Values](#parameters)  \n",
    "[Setting Coordinate Systems](#coordinates)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fishing Impact Workflow\n",
    "\n",
    "this hazard layer measures the intensity that a resource (in this case, FISH) is used or has the potential to be used, modified, or extracted.  \n",
    "high hazard values = high intensity use and potential for resournce manipulation  \n",
    "low hazard values  = low intensity use (or low likelihood or resource use) \n",
    "we use the Allen Atlas reef area layer as a proxy for the resource (FISH) \n",
    "\n",
    "1. Availability  (of the resournce, fish)  \n",
    "        > 1a. Marine benthic habitat  \n",
    "        > 1b. Geomorphic benthic habitat  \n",
    "        > 1c. Mangrove habitat\n",
    "        > 1d. Adjacent use areas  \n",
    "        all layers are scaled, then summed, and then scaled again (0-100)\n",
    "\n",
    "2. Access  \n",
    "        > 2a. Distance to coast  \n",
    "        > 2b. Population  \n",
    "        > 2c. Distance to major population centers (Provincial Capitals)\n",
    "        again, all layers are scaled, then combined, then scale again.   \n",
    "\n",
    " \n",
    "3. Combine 'Fishing Access' + 'Fish Resource'   \n",
    "        > in the forest example we multiplied. So there could ONLY be impact where there was forest.  \n",
    "        > but the boundaries in marine systems are very different, so there is not a clear boundary between resournce and not (Except for the coast).  so the layers are summed so that the potential for fish exists beyond the boundaries of reef areas.\n",
    "\n",
    "6. Rescale final 'fishing impact' layer to 0-100  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"workspace\"></a>\n",
    "\n",
    "# Set Workspaces\n",
    "\n",
    "1. Set variable names \n",
    "2. Put all your downloaded data into one file and load into GIS.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import arcpy\n",
    "import os\n",
    "from arcpy import env\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CheckedOut'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.CheckOutExtension(\"Spatial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting workspaces and folders to save data\n",
    "<a id= \"new_gdb\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, 9 April 2024 9:07:29 AM\",\"Succeeded at Tuesday, 9 April 2024 9:07:32 AM (Elapsed Time: 2.57 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\jc446202\\\\OneDrive - James Cook University (1)\\\\ACIAR_spatial\\\\modified_dat\\\\Fishing_ExPot.gdb'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a new workspace gdb file to put files into\n",
    "\n",
    "#keep commented out if you are working on this, but if this is the first time running this code, run the createfilegdb line\n",
    "#arcpy.management.CreateFileGDB(r\"C:\\Users\\jc446202\\OneDrive - James Cook University (1)\\ACIAR_spatial\\modified_dat\", \"Fishing_ExPot\", \"CURRENT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create file path directory to where you have saved your downloaded data \n",
    "#When running through this code, the new files will save into another folder\n",
    "\n",
    "##############################################\n",
    "#YOU NEED TO CHANGE THIS TO FIT YOUR COMPUTER#\n",
    "##############################################\n",
    "\n",
    "downloaded_data = r\"C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_Impact_Files\"\n",
    "#set your workspace, so everything will save to the new .gdb file you created\n",
    "forest_gdb = r\"C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Forest_ExPot.gdb\"        #or whatever output you want to save your files to. must be a .gdb file - create a .gdb folder.\n",
    "gdb_workspace = r\"C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\"             # r means read the raw file path name and doesnt interpret \\ as python syntax fxns\n",
    "\n",
    "arcpy.env.workspace = gdb_workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\n",
      "C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_Impact_Files\n",
      "C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\n"
     ]
    }
   ],
   "source": [
    "#check workspace\n",
    "print(arcpy.env.workspace)\n",
    "print(downloaded_data)\n",
    "print(gdb_workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"layersrequired\"></a>\n",
    "\n",
    "# Layers required\n",
    "\n",
    "**these files should be saved in a folder that only keeps downloaded data**  \n",
    "set the downloaded data file path in the cell above\n",
    "\n",
    "Shapefiles should be projected to WGS 1984 PDC Mercator  \n",
    "Load data to Arc Project (drag and drop from file or Add Data)  \n",
    "All files are in \"Fishing_Impact_Files\"  \n",
    "You should only have *ONE* folder. All these files get put in that folder and will run.  \n",
    "if you want to expand to another region, or do this for multiple years, those will need to be in separate folders  \n",
    "<br>\n",
    "\n",
    "\n",
    "Resource Layers\n",
    "------------------------\n",
    "\n",
    "1. Allen Coral Atlas benthic habitats data:  \n",
    "https://allencoralatlas.org/  \n",
    "Need to download Benthic map AND geomorphic map for area of interest \n",
    "data will download as a geojson  \n",
    "     - \"benthic.geojson\"  \n",
    "     - \"geomorphic.geojson\"  \n",
    "     - \"ES_benthi.geojson\" - the eastern solomons\n",
    "     - \"ES_geomorphic.geojson\" - the eastern solomons\n",
    "\n",
    "2. Mangrove habitat - 2020 v3  \n",
    "    - \"mangrove_shp_SI\"\n",
    "    - from global mangrove watch    \n",
    "    - https://www.globalmangrovewatch.org/   \n",
    "    - imported as a shapefile - gmw_v3_2020_vec  \n",
    "    - this needs to be clipped to the Solomon Island before running this code.   \n",
    "     \n",
    "2. Provincial capitals and major cities  \n",
    "    - this is for distance to city/market which has a negative impact on fish density/abundance/etc.\n",
    "    - https://solomons.gov.sb/wp-content/uploads/2023/09/  Solomon-Islands-2019-Population-Census-Report_Basic-Tables_Operations_Vol2.pdf  \n",
    "    - get the gps points of cities from: https://simplemaps.com/data/world-cities  \n",
    "    - cross reference the census cities, and add them to the gps points   \n",
    "    - only include cities with >5000 population  \n",
    "    - file:///C:/Users/jc446202/Downloads/Coral_reef_fish_value_chains_in_Solomon_Islands_Ma.pdf\n",
    "        - also discusses that there are a few large markets, but that large volumes of fish are sold at small market centers \n",
    "\n",
    "\n",
    "3. Major Roads   \n",
    "    - from open street map - same used in forest layer   \n",
    "    - https://planet.openstreetmap.org/   \n",
    "    - https://solomonislands-data.sprep.org/dataset/openstreetmap-data-solomon-islands  \n",
    "    - \"osm_SI_roads_p\"  - projected to correct coordinate system\n",
    "\n",
    "\n",
    "4. Solomon Islands country vector file, projected  \n",
    "    - name whatever you like, you will change the name later in the code  \n",
    "    - \"Solomons_country_p\"   \n",
    "   \n",
    "   \n",
    "5. Solomon Islands country LINE file, projected  \n",
    "    - name whatever you like, you will change the name later in the code  \n",
    "    - \"Solomons_line\"   \n",
    "  \n",
    "  \n",
    "6. Solomons Islands EEZ polygon area, projected  \n",
    "    - name whatever you like, you will change the name later in the code  \n",
    "    - \"Solomons_EEZ\"  \n",
    "     \n",
    "     \n",
    "7. Population count data - SPC  \n",
    "https://pacificdata.org/data/dataset/slb_population_grid_2020  \n",
    "Selections:  \n",
    "Year: 2020  \n",
    "FileFormat: GeoTiff  \n",
    "Resolution: 100 m  \n",
    "    - \"slb_rastpop2020rps_100m.tif\"   \n",
    "  \n",
    "  \n",
    "8. Enumeration Area polygon data  \n",
    "https://pacificdata.org/data/geographic_data/2009_slb_phc_admin_boundaries/resource/7b19ab32-2a3b-4afb-84d2-f4deef9050d8  \n",
    "Enumeration data is the lowest level of administrative boundary available for SI  \n",
    "    - \"SB_2009_EnumArea_4326.shp\"   \n",
    "\n",
    "  \n",
    "9. Sediment Export Plumes   \n",
    "https://github.com/WCS-Marine/local-reef-pressures/tree/main/data-raw  \n",
    "    - Results from this analysis are available as a scientific article: Andrello, M., Darling, E. S., Wenger, A., Suárez-Castro, A. F., Gelfand, S., & Ahmadia, G. N. (2022). A global map of human pressures on tropical coral reefs. Conservation Letters, Early view, e12858.  (https://doi.org/10.1111/conl.12858)  \n",
    "    - \"sed_plume_avg.tif\"\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"layerscreated\"></a>\n",
    "\n",
    "# Layers Created\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Layers\n",
    "\n",
    "\n",
    "| Layer_Name | File_Type | Description |\n",
    "|    :---    |  :---     |  :---   |\n",
    "|**country_poly**      | Polygon | country polygon - you set this name in Set Parameters              | \n",
    "|**country_EEZ**       | Polygon | EEZ polygon - you set this name in Set Parameters                  |\n",
    "|**country_line**      | Line    | line out country outline - you set this name in Set Parameters     |\n",
    "|**Suburb**            | Polygon | Enumeration Area government subdivision areas. smallest govmt area |\n",
    "|**Suburb_p**          | Polygon | projected Enumeration Area government subdivision areas            |\n",
    "|**coast_to_20k**      | Polygon | buffer from coastline to 20 km offshore                            |\n",
    "|**coast_buff_10k**    | Polygon | buffer from coastline to 10 km offshore                            |\n",
    "|**blank_rast_SI**     | Raster  | blank raster of Solomons EEZ of land and ocean, value = 1          |\n",
    "|**blank_rast_0**      | Raster  | blank raster of Solomons EEZ of land and ocean, value = 0          |\n",
    "|**blank_rast_land **  | Raster  | blank raster of Solomons EEZ of land only                          |\n",
    "|**blank_rast_ocean**  | Raster  | blank raster of Solomons EEZ of ocean only                         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reef Layers\n",
    "\n",
    "Benthic Layers  \n",
    "\n",
    "| Benthic Layers | File_Type | Description |\n",
    "|    :---    |  :---     |  :---   |\n",
    "|**benthic**                | Polygon   | benthic polygon data converted from geojson from Allen Atlas           |\n",
    "|**benthic_p**              | Polygon   | polygon file projected into WGS 1984 PDC Mercator                      |\n",
    "|**benthic_Dissolve**       | Polygon   | geomorphic data dissolved into multipart polys where 1 poly per class  |\n",
    "|**benthic_Dissolve_p**     | Polygon   | dissolved polygon data projected into WGS 1984 PDC Mercator            |\n",
    "|**benthic_SI**             | Polygon   | dissolved polygon benthic data clipped to Solomon Islands              |\n",
    "|**benthic_rast_SI**        | Raster    | dissolved polygon benthic data clipped to Solomon Islands              |\n",
    "|**benthic_rast**           | Raster    | Raster 50 m cell size of benthic data                                  |\n",
    "|**benthic_one_poly**       | Polygon   | One polygon of geomorphic layer                                        |\n",
    "  \n",
    " Geomorphic Layers  \n",
    "   \n",
    "| Geomorphic Layers | File_Type | Description |\n",
    "|    :---    |  :---     |  :---   |\n",
    "|**geomorphic**            | Polygon   | geomorphic polygon data converted from geojson from Allen Atlas         |\n",
    "|**geomorphic_p**          | Polygon   | polygon file projected into WGS 1984 PDC Mercator                       |\n",
    "|**geomorphic_Dissolve**   | Polygon   | benthic poly data dissolved into multipart polys of 1 poly per class    |\n",
    "|**geomorphic_Dissolve_p** | Polygon   | dissolved polygon data projected into WGS 1984 PDC Mercator             |\n",
    "|**geomorphic_SI**         | Polygon   | dissolved polygon geomorphic data clipped to Solomon Islands            |\n",
    "|**geomorphic_rast**       | Raster    | Raster 50 m cell size of geomorphic data                                |\n",
    "|**geomorphic_rast_SI**    | Raster    | Geomorphic rasters of Solomons reefs                                    |\n",
    "|**geomorphic_one_ploy**   | Polygon   | One polygon of geomorphic layer                                         |\n",
    "\n",
    "\n",
    "Adjacent Reef Measures  \n",
    "\n",
    "| Adjacent Reef Layers | File_Type | Description |\n",
    "|    :---:    |  :---:    |  :---:   |\n",
    "|**marine_hab_buff250m**       | Polygon  | buffer of 250 m around marine habitat (marine_hab_one_poly)                     |\n",
    "|**marine_reef_areas**         | Raster   | Raster (50 m cell size) of reef area (100) and 250 m buffer around reef (50)    |\n",
    "\n",
    "\n",
    "\n",
    "General Reef Layers\n",
    "\n",
    "| Layer_Name | File_Type | Description |\n",
    "|    :---    |  :---     |  :---   |\n",
    "|**marine_hab**            | Polygon   | marine habitat of Solomons- benthic and geomorphic separate polys       |\n",
    "|**marine_hab_one_poly**   | Polygon   | marine habitat of benthic and geomorphic as one poly                    |\n",
    "|**reef_area**            | Polygon   | combined benthic and geomorphic layers with rated values                |\n",
    "|**reef_area_scale**      | Polygon   | scaled combined benthic and geomprhic layers with raster values         |\n",
    "\n",
    "\n",
    "Final Resource Layer  \n",
    "  \n",
    "| Fish Resource Layer | File_Type | Description |\n",
    "|    :---:    |  :---:    |  :---:   |\n",
    "|**fish_resource_layer**  | Raster   | Final resource layer of reef layer scale + marine reef areas            |\n",
    "|**fish_resource_scaled** | Raster   | Scaled resource layer, 100 = high resource, 0 = low resource            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sediment Layers\n",
    "\n",
    "\n",
    "| Sediment Layers | File_Type | Description |\n",
    "|    :---:    |  :---:    |  :---:   |\n",
    "|**sed_plume_avg**               | Raster   | 1 km cell of sediment plume - global coral reefs            |\n",
    "|**sed_plume_avg_si**            | Raster   | 1 km cell of sediemnt plme in SOls EEZ                      |\n",
    "|**sed_plume_scale**             | Raster   | 1 km cell of scaled sediemnt plme in SOls EEZ               |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "## ACCESS LAYERS\n",
    "\n",
    "Distance Measures  \n",
    "\n",
    "| Distance Layers | File_Type | Description |\n",
    "|    :---:    |  :---:    |  :---:   |\n",
    "|**Dist_Coast_10k**               | Raster   | 50m cell distance from coastline to 10km offshore                                                   |\n",
    "|**Dist_Coast_10k**                | Raster   | Distance from coastline both ocean and land to 10000 m. 50 m cell size                              |\n",
    "|**Offshore_Dist_10k**             | Raster   | Distance from coastline over ocean only. 10000 m with 50m cell size                                 | \n",
    "|**dist_from_coast_scale**        | Raster   | Raster (50 m cell size) of benthic layer of Allen Atlas data. values are by fishing preference     | \n",
    "|**dist_from_coast_scale_full**   | Raster   | Scaled distance from coast (0 to 100) with 100 = near coast, 0 = far from coast at 5000m           | \n",
    "\n",
    "\n",
    "Population Measures  \n",
    "  \n",
    "| Population Measures | File_Type | Description |\n",
    "|    :---:    |  :---:    |  :---:   |\n",
    "|**Suburb_pop**                   | Polygon  | Enumeration Area w/population summed to each EA area (Field = Sum)                                 |\n",
    "|**pop_count_SI**                 | Raster   | raster of population count across Solomons                                                         | \n",
    "|**suburb_zonalstats_pop**        | Raster   | Enumeration area zones with total population per EA where pop data came from pop_count_SI          | \n",
    "|**Ocean_allocation_pop**         | Raster   | Raster (50 m cell size) where population per ea gets allocated to ocean area                       | \n",
    "|**ocean_pop_allo_10k**            | Raster   | Population allocation on ocean areas out to 10000 m (clipped layer from ocean_allocation_pop)       | \n",
    "|**ocean_pop_10k_scale**           | Raster   | Scaled ocean allocation. Where sum population values are scaled 0-100. 100 = high pop, 0 = low pop |\n",
    "\n",
    "\n",
    "Final Access Measures  \n",
    "  \n",
    "| Final Access Layers | File_Type | Description |\n",
    "|    :---:    |  :---:    |  :---:   |\n",
    "|**fish_access_layer**            | Raster   | Combined access layer of scaled layers: distance, geomorphic, benthic, ocean_allo_pop              | \n",
    "|**fish_access_scale**            | Raster   | Scaled access layer 0-100. 0 = low/no access. 100 = high/most access                               | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Fish Impact Layer\n",
    "\n",
    "\n",
    "| Final Fish Impact Layers | File_Type | Description |\n",
    "|    :---:    |  :---:    |  :---:   |\n",
    "|**fish_impact**            | Raster   | Combined fish access scale + fish resource scale. Note USE SUM because fishing can occur in all marine areas          | \n",
    "|**fish_impact_scale**      | Raster   | Scaled fish impact layers. 0-100. 100 = highest impact. 0 = lowest/no impact                                          | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"editing\"></a>\n",
    "\n",
    "\n",
    "# 1. Parameters that need Editing\n",
    "\n",
    "1. Need to set the file names for some layers\n",
    "2. Need to set certain parameter values \n",
    "\n",
    "### Need to rename the following layers:\n",
    "- country_polygon = 'Solomons_country_p'           \n",
    "- country_line = 'solomons_line'\n",
    "- EEZ = 'Solomons_EEZ_p'\n",
    "- Suburb = 'SB_2009_EnumArea_4326'\n",
    "\n",
    "#changing raster name\n",
    "- pop_count = 'slb_rastpop2020rps_100m.tif'\n",
    "\n",
    "### Need to set a value for the following parameters:\n",
    "\n",
    "Listed below are default values, but can be changed if desired  \n",
    "these values will vary based on expert and informed knowledge about ecological, biophysical and social parameters  \n",
    "\n",
    "**\"offshore_access_distance\"**  \n",
    "    Default =  10000\n",
    "    this is the distance fishers will travel from the coast to fish. \n",
    "    default is 10000 m (10 km)\n",
    "        \n",
    "**\"cell size\"**     \n",
    "    Default =  50m\n",
    "    \n",
    "**adjacent_reef_area**\n",
    "    Default = 250 m\n",
    "    this is the distance adjacent to reef locations that fishing is still likely to occur even the its classified as open ocean\n",
    "    \n",
    "**project_coord**  \n",
    "    Default = WGS_1984_PDC_Mercator\n",
    "    the projects coordinate system to use for this analysis\n",
    "      \n",
    "**gcs_coord**  \n",
    "    Default = GCS_WGS_1984\n",
    "    the geographic coordinate system. in case you need to convert\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"filenames\"></a>\n",
    "\n",
    "## Setting file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mangrove_p.shp', 'osm_SI_roads_p.shp', 'SB_2009_EnumArea_4326.shp', 'SI_Cities.shp', 'Solomons_country_p.shp', 'Solomons_EEZ_p.shp', 'solomons_line.shp']\n",
      "['sed_plume_avg.tif', 'slb_rastpop2020rps_100m.tif']\n"
     ]
    }
   ],
   "source": [
    "#list all files in downloaded data folder to check everything downloaded ok\n",
    "\n",
    "#set workspace to downloaded data file\n",
    "arcpy.env.workspace = downloaded_data\n",
    "\n",
    "#list feature classes\n",
    "featureclasses_downloaded = arcpy.ListFeatureClasses()\n",
    "print(featureclasses_downloaded)\n",
    "\n",
    "#list rasters\n",
    "downloaded_rasters = arcpy.ListRasters()\n",
    "print(downloaded_rasters)\n",
    "\n",
    "#this is a list of the all the files downloaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"filenames\"></a>\n",
    "\n",
    "## Setting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Distance travelled offshore\n",
    "\n",
    "#offshore_access_distance\n",
    "offshore_access_distance = 10000  #default is 10000 m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Adjacent reef area \n",
    "\n",
    "adjacent_reef_area = 250   #default is 250 m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>table td#td0  {font-weight: bold}</style><table class=\"notebook\"><colgroup><col style=\"width:45%\"></col><col style=\"width:55%\"></col></colgroup><tr><td id = \"td0\" title=\"name (Projected Coordinate System)\">name (Projected Coordinate System)</td><td title=\"WGS_1984_PDC_Mercator\">WGS_1984_PDC_Mercator</td></tr><tr><td id = \"td0\" title=\"factoryCode (WKID)\">factoryCode (WKID)</td><td title=\"3832\">3832</td></tr><tr><td id = \"td0\" title=\"linearUnitName (Linear Unit)\">linearUnitName (Linear Unit)</td><td title=\"Meter\">Meter</td></tr></table><div class=\"subtitle\">spatialReference.GCS</div><style>table td#td0  {font-weight: bold}</style><table class=\"notebook\"><colgroup><col style=\"width:45%\"></col><col style=\"width:55%\"></col></colgroup><tr><td id = \"td0\" title=\"name (Geographic Coordinate System)\">name (Geographic Coordinate System)</td><td title=\"GCS_WGS_1984\">GCS_WGS_1984</td></tr><tr><td id = \"td0\" title=\"factoryCode (WKID)\">factoryCode (WKID)</td><td title=\"4326\">4326</td></tr><tr><td id = \"td0\" title=\"angularUnitName (Angular Unit)\">angularUnitName (Angular Unit)</td><td title=\"Degree\">Degree</td></tr><tr><td id = \"td0\" title=\"datumName (Datum)\">datumName (Datum)</td><td title=\"D_WGS_1984\">D_WGS_1984</td></tr></table>"
      ],
      "text/plain": [
       "<SpatialReference object at 0x11489fb0340[0x114fbfb4f10]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Projected coordinate system\n",
    "\n",
    "project_coord = arcpy.SpatialReference('WGS_1984_PDC_Mercator')  #default = 'WGS_1984_PDC_Mercator'\n",
    "project_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>table td#td0  {font-weight: bold}</style><table class=\"notebook\"><colgroup><col style=\"width:45%\"></col><col style=\"width:55%\"></col></colgroup><tr><td id = \"td0\" title=\"name (Geographic Coordinate System)\">name (Geographic Coordinate System)</td><td title=\"GCS_WGS_1984\">GCS_WGS_1984</td></tr><tr><td id = \"td0\" title=\"factoryCode (WKID)\">factoryCode (WKID)</td><td title=\"4326\">4326</td></tr><tr><td id = \"td0\" title=\"angularUnitName (Angular Unit)\">angularUnitName (Angular Unit)</td><td title=\"Degree\">Degree</td></tr><tr><td id = \"td0\" title=\"datumName (Datum)\">datumName (Datum)</td><td title=\"D_WGS_1984\">D_WGS_1984</td></tr></table>"
      ],
      "text/plain": [
       "<SpatialReference object at 0x212f7a117c0[0x212eeaebe30]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Geographic coordinate system\n",
    "\n",
    "gcs_coord = arcpy.SpatialReference('GCS_WGS_1984') #default = 'GCS_WGS_1984'\n",
    "gcs_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\n",
      "C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_Impact_Files\n"
     ]
    }
   ],
   "source": [
    "print(gdb_workspace)\n",
    "print(downloaded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"manipulations\"></a>\n",
    "\n",
    "# 2. Manipulating downloaded data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"movelayers\"></a>\n",
    "\n",
    "## Moving downloaded data to gdb and saving as new file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 'mangrove_p.shp' projected and saved to 'C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\\mangrove_p_shp'\n",
      "Layer 'mangrove_shp_SI.shp' projected and saved to 'C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\\mangrove_shp_SI_shp'\n",
      "Layer 'mangrove_shp_SI_p.shp' projected and saved to 'C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\\mangrove_shp_SI_p_shp'\n",
      "Layer 'osm_SI_roads_p.shp' projected and saved to 'C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\\osm_SI_roads_p_shp'\n",
      "Layer 'SB_2009_EnumArea_4326.shp' projected and saved to 'C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\\SB_2009_EnumArea_4326_shp'\n",
      "Layer 'SI_Cities.shp' projected and saved to 'C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\\SI_Cities_shp'\n",
      "Layer 'Solomons_country_p.shp' projected and saved to 'C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\\Solomons_country_p_shp'\n",
      "Layer 'Solomons_EEZ_p.shp' projected and saved to 'C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\\Solomons_EEZ_p_shp'\n",
      "Layer 'solomons_line.shp' projected and saved to 'C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\\solomons_line_shp'\n",
      "Layer 'World_Cities.shp' projected and saved to 'C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\\World_Cities_shp'\n",
      "Conversion complete.\n"
     ]
    }
   ],
   "source": [
    "for layer in featureclasses_downloaded:\n",
    "    # Get the full path of the input layer\n",
    "    input_layer_path = os.path.join(downloaded_data, layer)\n",
    "    \n",
    "    # Generate a new name for the output layer\n",
    "    output_layer_name = arcpy.ValidateTableName(layer, gdb_workspace)\n",
    "    \n",
    "    # Set the output layer path in the geodatabase\n",
    "    output_layer_path = os.path.join(gdb_workspace, output_layer_name)\n",
    "    \n",
    "    # Project the layer to the target spatial reference\n",
    "    arcpy.management.Project(input_layer_path, output_layer_path, project_coord)\n",
    "    \n",
    "    print(f\"Layer '{layer}' projected and saved to '{output_layer_path}'\")\n",
    "\n",
    "print(\"Conversion complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mangrove_p_shp', 'osm_SI_roads_p_shp', 'SB_2009_EnumArea_4326_shp', 'SI_Cities_shp', 'Solomons_country_p_shp', 'Solomons_EEZ_p_shp', 'solomons_line_shp']\n",
      "['sed_plume_avg_tif', 'slb_rastpop2020rps_100m_tif']\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = gdb_workspace\n",
    "gdb_features = arcpy.ListFeatureClasses()\n",
    "print(gdb_features)\n",
    "\n",
    "gdb_rasters = arcpy.ListRasters()\n",
    "print(gdb_rasters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 'sed_plume_avg.tif' projected and saved to 'C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\\sed_plume_avg_tif'\n",
      "Layer 'slb_rastpop2020rps_100m.tif' projected and saved to 'C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\\slb_rastpop2020rps_100m_tif'\n",
      "Conversion complete.\n"
     ]
    }
   ],
   "source": [
    "#move rasters to geodatabase\n",
    "#this gets the rasters we want to move, projects them, and then copies them to geodatabase (ExPot)\n",
    "#\n",
    "for layer in downloaded_rasters:\n",
    "    # Get the full path of the input layer\n",
    "    input_layer_path = os.path.join(downloaded_data, layer)\n",
    "    \n",
    "    # Generate a new name for the output layer\n",
    "    output_layer_name = arcpy.ValidateTableName(layer, gdb_workspace)\n",
    "    \n",
    "    # Set the output layer path in the geodatabase\n",
    "    output_layer_path = os.path.join(gdb_workspace, output_layer_name)\n",
    "    \n",
    "    # Project the layer to the target spatial reference\n",
    "    arcpy.management.ProjectRaster(input_layer_path, output_layer_path, project_coord)\n",
    "    \n",
    "    print(f\"Layer '{layer}' projected and saved to '{output_layer_path}'\")\n",
    "\n",
    "print(\"Conversion complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Renaming the files in the gdb folder\n",
    "\n",
    "arcpy.env.workspace = gdb_workspace\n",
    "\n",
    "#HERE you need to CHANGE THE NAMES OF THE FILES on the right of the = sign \n",
    "#using the names of the files you have downloaded\n",
    "#only need to change the below files\n",
    "\n",
    "#naming the files so can call them easily later (note - does NOT acutally change the name, just makes it an object)\n",
    "country_polygon = 'Solomons_country_p_shp'            #this is where you will change the name of the shapefile you have downloaded. \n",
    "country_line = 'solomons_line_shp'\n",
    "EEZ = 'Solomons_EEZ_p_shp'\n",
    "Suburb = 'SB_2009_EnumArea_4326_shp'\n",
    "roads = 'osm_SI_roads_p_shp'\n",
    "cities = 'SI_Cities_shp'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"reefhab_convert\"></a>\n",
    "\n",
    "\n",
    "## Allen Atlas Data Management\n",
    "\n",
    "1. need to move the geojson file from downloaded data and turn in to polygon file in geodatabase folder  \n",
    "2. dissolve the data. the polygon files have >400,000 objects, and want to combine all polygons by type so its more manageable to process  \n",
    "3. be aware this is a computational intensive process. will take time and make sure not to run again if going through this code more than once.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_Impact_Files\n",
      "['benthic.geojson', 'geomorphic.geojson']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = downloaded_data\n",
    "print(downloaded_data)\n",
    "\n",
    "#list all allen atlas data in the downloaded data file (fishing_impact_files)\n",
    "Allen_List = arcpy.ListFiles(\"*geojson\") # * is a wild cards. says select anything that has \"...geojson\" and any value before that.\n",
    "print(Allen_List)\n",
    "print(len(Allen_List))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : D:\\ACIAR\\modified_dat\\Fishing_Impact.gdb\\benthic\n",
      "Processing : D:\\ACIAR\\modified_dat\\Fishing_Impact.gdb\\geomorphic\n"
     ]
    }
   ],
   "source": [
    "#renames files and converts to polygon into downloaded data file\n",
    "#keeping as commented right now, because it takes a long while to run and dont want to accidentally run twice\n",
    "\n",
    "\n",
    "#for f in arcpy.ListFiles('*.geojson'):                                                 # lists all geojsons in the active workspace (downloaded data)\n",
    "    #root_extension = os.path.splitext(f)                                               # separates root and extension of file names\n",
    "    #output_poly = os.path.join(os.path.dirname(f), root_extension[0])                  # creates new list of file directory and root names of geojson files\n",
    "    #print(\"Processing : {}\".format(output_poly))                                       # lets you know which file is being processed\n",
    "    \n",
    "    #arcpy.conversion.JSONToFeatures(f, output_poly)                                    # converts geojson to poly and store in same directory\n",
    "    \n",
    "    #arcpy.management.Project(output_poly, output_poly, project_coord)                  #project the feature class to the specific coordinate system PDC mercator\n",
    "\n",
    "    #dissolved_layer = os.path.join(gdb_workspace, root_extension[0] + \"_dissolve\")    # assign layer name to identify layers to dissolve\n",
    "    #arcpy.management.Dissolve(output_poly, dissolve_layer, \"class\", None, \"MULTI_PART\")#dissolve layer by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, 26 July 2023 9:21:56 AM\",\"WARNING 003598: Updated feature class extent.\",\"Succeeded at Wednesday, 26 July 2023 9:25:53 AM (Elapsed Time: 3 minutes 57 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'geomorphic'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#repair geometries\n",
    "#for some reason the polygons might have weird geometries and need repairing (e.g. self intersections)\n",
    "#arcpy.management.RepairGeometry(\"benthic\", \"DELETE_NULL\", \"ESRI\")\n",
    "#arcpy.management.RepairGeometry(\"geomorphic\", \"DELETE_NULL\", \"ESRI\")\n",
    "\n",
    "#might not be necessary, and if it isnt, then it wont modify the input. Does take some time. so dont run unless the next cell chunk doesnt run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Clip marine hab layers to Solomons Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, 26 July 2023 10:58:27 AM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Wednesday, 26 July 2023 11:06:50 AM (Elapsed Time: 8 minutes 23 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'D:\\\\ACIAR\\\\modified_dat\\\\Fishing_Impact.gdb\\\\benthic_SI'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BENTHIC CLIP\n",
    "\n",
    "arcpy.analysis.Clip('benthic_dissolve', 'country_EEZ', \"benthic_SI\")\n",
    "arcpy.management.Delete('benthic_dissolve)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, 26 July 2023 11:08:42 AM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Wednesday, 26 July 2023 11:12:05 AM (Elapsed Time: 3 minutes 22 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'D:\\\\ACIAR\\\\modified_dat\\\\Fishing_Impact.gdb\\\\geomorphic_SI'>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GEOMORPHIC CLIP\n",
    "\n",
    "arcpy.analysis.Clip('geomorphic_dissolve', 'country_EEZ', \"geomorphic_SI\")\n",
    "arcpy.management.Delete('geomorphic_dissolve)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erase mangrove from Land Area  \n",
    "\n",
    "want to have mangrove NOT in land areas  \n",
    "doing this for a few reasons:  \n",
    "    1. Already have mangrove in forest estimations  - so dont want to double up mangrove effect   \n",
    "    2. Mangroves in the indo pacific have slightly less tidal range than other areas (Igulu) and perhaps just having the \"marine\" non land mangrove area is enough  \n",
    "    3. But IF I HAVE TIME - i should go through some literature to see if i need to include the 'land' mangrove areas.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, 12 February 2024 11:11:27 AM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Monday, 12 February 2024 11:11:31 AM (Elapsed Time: 3.58 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_Impact.gdb\\\\Mangrove_p_Erase'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MANGROVE ERASE\n",
    "\n",
    "arcpy.analysis.Erase('mangrove_p_shp', 'country_poly', \"Mangrove_p_Erase\")\n",
    "arcpy.management.Delete('mangrove_p_shp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"popconvert\"></a>\n",
    "\n",
    "\n",
    "## Population Manipulation\n",
    "\n",
    "1. need to clip the data to solomons only area\n",
    "2. when clip, save it to gdb folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, 9 April 2024 4:43:45 PM\",\"Succeeded at Tuesday, 9 April 2024 4:43:46 PM (Elapsed Time: 0.51 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'true'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clip raster data to only area of Solomons \n",
    "#and save it to the geodatabase\n",
    "\n",
    "arcpy.env.workspace = gdb_workspace\n",
    "\n",
    "out_raster = arcpy.sa.ExtractByMask('slb_rastpop2020rps_100m_tif', EEZ, \"INSIDE\"); out_raster.save(os.path.join(gdb_workspace, \"pop_count_SI\"))\n",
    "#os.path.join means its saving the raster to the gdb workspace and making the file name pop_count_SI\n",
    "\n",
    "arcpy.management.Delete('slb_rastpop2020rps_100m_tif')                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"sed_clean\"></a>\n",
    "\n",
    "## Cleaning sediment layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, 9 April 2024 4:45:23 PM\",\"Succeeded at Tuesday, 9 April 2024 4:45:24 PM (Elapsed Time: 0.40 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'true'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clip sediment layer to solomon islands EEZ\n",
    "\n",
    "arcpy.env.workspace = gdb_workspace\n",
    "arcpy.management.Clip(\"sed_plume_avg_tif\", EEZ, \"sed_plume_SI\")\n",
    "arcpy.management.Delete('sed_plume_avg_tif')            #remove original sediment layer          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['pop_count_SI', 'sed_plume_SI']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(arcpy.env.workspace)\n",
    "arcpy.ListRasters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"coordinates\"></a>\n",
    "\n",
    "\n",
    "## Setting Coordinate References and Converting to Projection if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>table td#td0  {font-weight: bold}</style><table class=\"notebook\"><colgroup><col style=\"width:45%\"></col><col style=\"width:55%\"></col></colgroup><tr><td id = \"td0\" title=\"name (Geographic Coordinate System)\">name (Geographic Coordinate System)</td><td title=\"GCS_WGS_1984\">GCS_WGS_1984</td></tr><tr><td id = \"td0\" title=\"factoryCode (WKID)\">factoryCode (WKID)</td><td title=\"4326\">4326</td></tr><tr><td id = \"td0\" title=\"angularUnitName (Angular Unit)\">angularUnitName (Angular Unit)</td><td title=\"Degree\">Degree</td></tr><tr><td id = \"td0\" title=\"datumName (Datum)\">datumName (Datum)</td><td title=\"D_WGS_1984\">D_WGS_1984</td></tr></table>"
      ],
      "text/plain": [
       "<SpatialReference object at 0x1e932d18b80[0x1e932f8e970]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check projection reference - make sure this is correct.\n",
    "\n",
    "project_coord\n",
    "\n",
    "gcs_coord \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coordinates for vector files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mangrove_p_shp : WGS_1984_PDC_Mercator\n",
      "osm_SI_roads_p_shp : WGS_1984_PDC_Mercator\n",
      "SB_2009_EnumArea_4326_shp : WGS_1984_PDC_Mercator\n",
      "SI_Cities_shp : WGS_1984_PDC_Mercator\n",
      "Solomons_country_p_shp : WGS_1984_PDC_Mercator\n",
      "Solomons_EEZ_p_shp : WGS_1984_PDC_Mercator\n",
      "solomons_line_shp : WGS_1984_PDC_Mercator\n",
      "benthic_dissolve : WGS_1984_PDC_Mercator\n",
      "geomorphic_dissolve : WGS_1984_PDC_Mercator\n"
     ]
    }
   ],
   "source": [
    "#for vector files: check spatial reference\n",
    "\n",
    "#make sure youre in the right workspace (gdb file)\n",
    "arcpy.env.workspace = gdb_workspace\n",
    "\n",
    "#list vectors in gdb\n",
    "feature_class_gdb = arcpy.ListFeatureClasses()\n",
    "\n",
    "#Loop through the list\n",
    "for fc in feature_class_gdb:\n",
    "    # Create the spatial reference object\n",
    "    spatial_ref = arcpy.Describe(fc).spatialReference\n",
    "\n",
    "    # If the spatial reference is unknown\n",
    "    if spatial_ref.name == \"Unknown\":\n",
    "        print(\"{} has an unknown spatial reference\".format(fc))\n",
    "\n",
    "    # Otherwise, print out the feature class name and spatial reference\n",
    "    else:\n",
    "        print(\"{} : {}\".format(fc, spatial_ref.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mangrove_p_shp is already in correct projection\n",
      "osm_SI_roads_p_shp is already in correct projection\n",
      "SB_2009_EnumArea_4326_shp is already in correct projection\n",
      "SI_Cities_shp is already in correct projection\n",
      "Solomons_country_p_shp is already in correct projection\n",
      "Solomons_EEZ_p_shp is already in correct projection\n",
      "solomons_line_shp is already in correct projection\n",
      "benthic_dissolve is already in correct projection\n",
      "geomorphic_dissolve is already in correct projection\n"
     ]
    }
   ],
   "source": [
    "#convert non projected data to projected data (PDC mercator)\n",
    "\n",
    "#Loop through the list\n",
    "for infc in feature_class_gdb:                                            \n",
    "    #determine if input has a defined coordinate system\n",
    "    spatial_ref = arcpy.Describe(infc).spatialReference\n",
    "\n",
    "    # If the spatial reference is not the correct projected coordinate system\n",
    "    if spatial_ref.name == project_coord.name:\n",
    "        print(\"{} is already in correct projection\".format(infc))\n",
    "    \n",
    "    else:\n",
    "        # determine new output feature class (outfc) path and name. \n",
    "        #this saves to same gdb, saves as same name, and then add \"_p\" to the end to indicate its projected\n",
    "        outfc = os.path.join(gdb_workspace, infc+'_p')\n",
    "        \n",
    "        # set projected coord system to use\n",
    "        outCS = project_coord\n",
    "        \n",
    "        #run project tool\n",
    "        arcpy.management.Project(infc, outfc, outCS)\n",
    "        print(\"{} has been  converted and is now: {}\".format(infc, outfc))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coordinates for raster files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pop_count_SI', 'sed_plume_SI']\n",
      "pop_count_SI : WGS_1984_PDC_Mercator\n",
      "sed_plume_SI : WGS_1984_PDC_Mercator\n"
     ]
    }
   ],
   "source": [
    "#check spatial reference of raster  files:\n",
    "\n",
    "#make sure youre in the right workspace (gdb file)\n",
    "arcpy.env.workspace = gdb_workspace\n",
    "\n",
    "\n",
    "#list rasters in gdb\n",
    "raster_gdb = arcpy.ListRasters()\n",
    "print(raster_gdb)\n",
    "\n",
    "#Loop through the list\n",
    "for fc in raster_gdb:\n",
    "    # Create the spatial reference object\n",
    "    spatial_ref_rast = arcpy.Describe(fc).spatialReference\n",
    "\n",
    "    # If the spatial reference is unknown\n",
    "    if spatial_ref_rast.name == \"Unknown\":\n",
    "        print(\"{} has an unknown spatial reference\".format(fc))\n",
    "\n",
    "    # Otherwise, print out the feature class name and spatial reference\n",
    "    else:\n",
    "        print(\"{} : {}\".format(fc, spatial_ref_rast.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pop_count_SI is already in correct projection\n",
      "sed_plume_SI is already in correct projection\n"
     ]
    }
   ],
   "source": [
    "#convert non projected data to projected data (PDC mercator)\n",
    "\n",
    "#Loop through the list\n",
    "for infc in raster_gdb:                                            \n",
    "    #determine if input has a defined coordinate system\n",
    "    spatial_ref = arcpy.Describe(infc).spatialReference\n",
    "\n",
    "    # If the spatial reference is not the correct projected coordinate system\n",
    "    if spatial_ref.name == project_coord.name:\n",
    "        print(\"{} is already in correct projection\".format(infc))\n",
    "    \n",
    "    else:\n",
    "        # determine new output feature class (outfc) path and name. \n",
    "        #this saves to same gdb, saves as same name, and then add \"_p\" to the end to indicate its projected\n",
    "        outfc = os.path.join(gdb_workspace, infc+'_p')\n",
    "        \n",
    "        # set projected coord system to use\n",
    "        outCS = project_coord\n",
    "        \n",
    "        #run project tool\n",
    "        arcpy.management.ProjectRaster(infc, outfc, outCS)\n",
    "        print(\"{} has been converted and is now: {}\".format(infc, outfc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"blankrasters\"></a>\n",
    "\n",
    "## Generating Blank Rasters\n",
    "\n",
    "1. create full blank raster (value = 0) across entirety of Solomons EEZ\n",
    "2. Create ocean blank raster (no cells for land areas)\n",
    "3. create land balnk raster (no cells for ocean area) --- tbd on whether i need this one or not. probs for the land based one? to have adj ares and roads become full raster area. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, 9 April 2024 4:53:00 PM\",\"Succeeded at Tuesday, 9 April 2024 4:53:26 PM (Elapsed Time: 26.33 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\\\\blank_rast_0'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Generating Blank raster of Solomons\n",
    "arcpy.conversion.PolygonToRaster(EEZ, \"OBJECTID\", \"blank_rast_SI\", \"CELL_CENTER\", \"NONE\", 50, \"BUILD\")\n",
    "#turn value of blank raster into 0 (changes from 1 to 0)\n",
    "arcpy.ddd.Reclassify(\"blank_rast_SI\", \"Value\", \"1 0\", \"blank_rast_0\", \"DATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, 10 April 2024 10:28:23 AM\",\"Succeeded at Wednesday, 10 April 2024 10:28:34 AM (Elapsed Time: 11.04 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\\\\blank_rast_land'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Generating a Blank raster of land \n",
    "arcpy.conversion.PolygonToRaster(country_polygon, \"OBJECTID\", \"blank_rast_land\", \"CELL_CENTER\", \"NONE\", 50, \"BUILD\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#clip raster to ocean area\n",
    "out_raster = arcpy.sa.ExtractByMask(\"blank_rast_0\", country_polygon, \"OUTSIDE\"); out_raster.save(\"blank_rast_ocean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"ReefLayer\"></a>\n",
    "\n",
    "\n",
    "# 3. Availability (Reef Area)  \n",
    "\n",
    "**a. benthic layer + geomorphic layer edits  (Reef layer)  \n",
    "  b. adjacent to habitat layer  (Fish layer)  \n",
    "  c. mangrove layer  \n",
    "  c. combine reef and fish layers**  \n",
    "  \n",
    "  \n",
    "i.    edit benthic & geomorphic layer so hab types are classified into values  \n",
    "ii.   clip polygon layer to Solomons Islands country layer  \n",
    "iii.  assign value to mangrove layer  = 2  \n",
    "iii.  convert benthic, geomorphic, and mangrove layers into raster and clip to solomons area \n",
    "iv.   combine benthic, geormorphic, and magrove rasters  \n",
    "v.    scale marine habitat layer raster 0-100 (\"reef area\")  \n",
    "  \n",
    "vi.    create one polygon for all reef areas  \n",
    "vii.   create buffer of reef area = 250 m  \n",
    "viii.  turn buffer area into raster with value of 100= reef, 50 = adjacent buffer, 0 outside both  \n",
    "  \n",
    "ix.    combine reef area scaled layer with adjacent reef layer  \n",
    "x.     scale full layer (100-0)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"allen\"></a>\n",
    "\n",
    "## 3A. Reef layer edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#BENTHIC HABITAT\n",
    "\n",
    "#add new field called class_num\n",
    "arcpy.management.AddField('benthic_SI', \"Class_Num\", \"SHORT\")\n",
    "\n",
    "#update Class num field\n",
    "fc = 'benthic_SI'\n",
    "fields = ['class', 'Class_Num']\n",
    "\n",
    "with arcpy.da.UpdateCursor(fc, fields) as cursor:\n",
    "    #for each row, evaluate the \"class\" field value (index position of 0)\n",
    "    #and update \"Class_Num\" field value (index position of 1 in fields df)\n",
    "    for row in cursor:\n",
    "        if (row[0] == \"Coral/Algae\"):\n",
    "            row[1] = \"3\"\n",
    "        elif (row[0] == \"Microalgal Mats\"):\n",
    "            row[1] = \"2\"\n",
    "        elif (row[0] == \"Rock\"):\n",
    "            row[1] = \"1\"\n",
    "        elif (row[0] == \"Rubble\"):\n",
    "            row[1] = \"1\"\n",
    "        elif (row[0] == \"Sand\"):\n",
    "            row[1] = \"1\"\n",
    "        elif (row[0] == \"Seagrass\"):\n",
    "            row[1] = \"2\"      \n",
    "        #update cursor with the updated list\n",
    "        cursor.updateRow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GEOMORPHIC HABITAT\n",
    "\n",
    "#add new field called class_num\n",
    "arcpy.management.AddField('geomorphic_SI', \"Class_Num\", \"SHORT\")\n",
    "\n",
    "fc = 'geomorphic_SI'\n",
    "fields = ['class', 'Class_Num']\n",
    "\n",
    "with arcpy.da.UpdateCursor(fc, fields) as cursor:\n",
    "    #for each row, evaluate the \"class\" field value (index position of 0)\n",
    "    #and update \"Class_Num\" field value (index position of 1 in fields df)\n",
    "    for row in cursor:\n",
    "        if (row[0] == \"Back Reef Slope\"):\n",
    "            row[1] = \"2\"\n",
    "        elif (row[0] == \"Deep Lagoon\"):\n",
    "            row[1] = \"2\"\n",
    "        elif (row[0] == \"Inner Reef Flat\"):\n",
    "            row[1] = \"1\"\n",
    "        elif (row[0] == \"Outer Reef Flat\"):\n",
    "            row[1] = \"1\"\n",
    "        elif (row[0] == \"Plateau\"):\n",
    "            row[1] = \"2\"\n",
    "        elif (row[0] == \"Reef Crest\"):\n",
    "            row[1] = \"3\" \n",
    "        elif (row[0] == \"Reef Slope\"):\n",
    "            row[1] = \"3\" \n",
    "        elif (row[0] == \"Shallow Lagoon\"):\n",
    "            row[1] = \"2\" \n",
    "        elif (row[0] == \"Sheltered Reef Slope\"):\n",
    "            row[1] = \"3\"      \n",
    "        elif (row[0] == \"Terrestrial Reef Flat\"):\n",
    "            row[1] = \"1\"             \n",
    "        #update cursor with the updated list\n",
    "        cursor.updateRow(row)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MANGROVE HABITAT\n",
    "\n",
    "#add new field called class_num\n",
    "arcpy.management.AddField(Mangrove, \"Class_Num\", \"SHORT\")\n",
    "\n",
    "#update Class num field\n",
    "fc = Mangrove\n",
    "field = ['Class_Num']\n",
    "\n",
    "\n",
    "#Set mangrove area value to 2\n",
    "\n",
    "with arcpy.da.UpdateCursor(fc, field) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] is None:  # Check for None values explicitly\n",
    "            row[0] = 2\n",
    "            cursor.updateRow(row)  # Update the row\n",
    "print(\"Field 'Class Num' has been added and updated with the value of 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, 26 July 2023 11:12:54 AM\",\"Succeeded at Wednesday, 26 July 2023 12:08:26 PM (Elapsed Time: 55 minutes 32 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'D:\\\\ACIAR\\\\modified_dat\\\\Fishing_Impact.gdb\\\\benthic_rast'>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert to raster - benthic\n",
    "#cell size = 50 m\n",
    "\n",
    "arcpy.conversion.PolygonToRaster(\"benthic_SI\", \"Class_Num\", \"benthic_rast\", \"CELL_CENTER\", \"NONE\", 50, \"BUILD\")\n",
    "#note, this takes about 1 hour to complete "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, 26 July 2023 12:34:20 PM\",\"Succeeded at Wednesday, 26 July 2023 12:56:10 PM (Elapsed Time: 21 minutes 50 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'D:\\\\ACIAR\\\\modified_dat\\\\Fishing_Impact.gdb\\\\geomorphic_rast'>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert to raster = geomorphic\n",
    "#cell size = 50 m\n",
    "\n",
    "arcpy.conversion.PolygonToRaster(\"geomorphic_SI\", \"Class_Num\", \"geomorphic_rast\", \"CELL_CENTER\", \"NONE\", 50, \"BUILD\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, 12 February 2024 11:12:26 AM\",\"Succeeded at Monday, 12 February 2024 11:12:30 AM (Elapsed Time: 4.68 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_Impact.gdb\\\\mangrove_rast'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert to raster = mangrove\n",
    "#cell size = 50 m\n",
    "\n",
    "arcpy.conversion.PolygonToRaster(\"Mangrove_p_Erase\", \"Class_Num\", \"mangrove_rast\", \"CELL_CENTER\", \"NONE\", 50, \"BUILD\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\n"
     ]
    }
   ],
   "source": [
    "print(gdb_workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Benthic, Geomorphic, and Mangrove Rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Adding rasters together, but also adding with blank raster to create a full coverage\n",
    "out_raster = arcpy.ia.CellStatistics(\"blank_rast_ocean;geomorphic_rast;benthic_rast;mangrove_rast\",\"SUM\", \"DATA\", \"SINGLE_BAND\", 90, \"AUTO_DETECT\");\n",
    "out_raster.save(\"marine_hab\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Fishing Resource Raster\n",
    "\n",
    "1. extract statistics data to scale values\n",
    "2. scale values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "#identify min and max values of fishing_resource\n",
    "\n",
    "reef_area_min_output = arcpy.management.GetRasterProperties('marine_hab', 'MINIMUM',\"\") #extracts minimum value from raster\n",
    "reef_area_min = int(reef_area_min_output.getOutput(0)) #assigns that value to an object, and converts to a integer\n",
    "print(reef_area_min)\n",
    "\n",
    "reef_area_max_ouput = arcpy.management.GetRasterProperties('marine_hab', 'MAXIMUM',\"\")\n",
    "reef_area_max = int(reef_area_max_ouput.getOutput(0))\n",
    "print(reef_area_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "#checking object type to confirm integer\n",
    "print(type(reef_area_min))\n",
    "print(type(reef_area_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scale reef layer raster from 0 - 100 \n",
    "\n",
    "outraster = ((arcpy.Raster(\"marine_hab\") - float(reef_area_min))/(float(reef_area_max) - float(reef_area_min)))*100; outraster.save(\"marine_hab_scale\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"adj_reef\"></a>\n",
    "\n",
    "## 3b. Adjacent to Reef Area\n",
    "\n",
    "want to create a layer showing some fishing effort in the adjacent reef area\n",
    "remember the resource is FISH  \n",
    "so adjacent to the reef area is still a location where there are fish, and people are fishing,  \n",
    "the hazard of extraction of the fish resource is possible. \n",
    "\n",
    "Adjacent reef area cutoff distance = 250 m. \n",
    "\n",
    "fish area\n",
    "    reef = 100\n",
    "    adjacent areas = 50\n",
    "    aka reef areas are twice as likely to have a fish resource compared to adjacent areas\n",
    "\n",
    "when we combine fish layer with the reef_layer (benthic and geomorphic layers classed by high fish areas) (100-0)\n",
    "    we get max possible value for a reef area to be 200, and the adjacent area = 50. \n",
    "    meaning that the adjacent area is 25% as good as a high fish reef area (coral reef slope)\n",
    "    and potentially as good for fish as a low value fish area (rubble reef flat)\n",
    "\n",
    "steps:\n",
    "1. dissolve all poly of geo and benthic.\n",
    "2. merge benthic and geo, and dissolve\n",
    "3. create 250 buff outside polys\n",
    "4. merge reef poly and buff poly\n",
    "5. reef poly = 100, buff poly = 50\n",
    "6. convert reef+adj poly into raster\n",
    "\n",
    "7. combine rast with reef_layer\n",
    "8. scale combined layer (100-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, 10 April 2024 11:50:03 AM\",\"Dissolving...\",\"Succeeded at Wednesday, 10 April 2024 11:50:05 AM (Elapsed Time: 1.75 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\\\\mangrove_onepoly'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. dissolve all poly of geo and benthic\n",
    "arcpy.management.Dissolve(\"geomorphic_SI\", \"geomorphic_onepoly\", \"\", None, \"MULTI_PART\", \"DISSOLVE_LINES\", '')\n",
    "arcpy.management.Dissolve(\"benthic_SI\", \"benthic_onepoly\", \"\", None, \"MULTI_PART\", \"DISSOLVE_LINES\", '')\n",
    "arcpy.management.Dissolve(\"Mangrove_p_Erase\", \"mangrove_onepoly\", \"\", None, \"MULTI_PART\", \"DISSOLVE_LINES\", '')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, 10 April 2024 2:48:54 PM\",\"Succeeded at Wednesday, 10 April 2024 2:48:54 PM (Elapsed Time: 0.31 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'true'>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Delete mangrove_p_Erase\n",
    "\n",
    "arcpy.management.Delete(\"mangrove_p_Erase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, 10 April 2024 12:29:23 PM\",\"Succeeded at Wednesday, 10 April 2024 12:29:23 PM (Elapsed Time: 0.23 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'true'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. merge benthic, geomorphic, and mangrove, and dissolve\n",
    "arcpy.management.Merge(\"benthic_onepoly;geomorphic_onepoly;mangrove_onepoly\", \"marine_habitats\", None, \"NO_SOURCE_INFO\")\n",
    "\n",
    "#dissolve all polygons so get one large polygon of all marine habitats\n",
    "arcpy.management.Dissolve(\"marine_habitats\", \"marine_hab_onepoly\", None, None, \"MULTI_PART\", \"DISSOLVE_LINES\", '')\n",
    "\n",
    "#delete intermediate layer\n",
    "arcpy.management.Delete(\"marine_habitats\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise buffer analysis complete.\n"
     ]
    }
   ],
   "source": [
    "#3. create 250 buff outside polys\n",
    "#dissolved into only polygon\n",
    "\n",
    "arcpy.analysis.PairwiseBuffer(\"marine_hab_onepoly\", \"marine_hab_buff250m\", \"250 Meters\", \"ALL\", None, \"PLANAR\", \"0 Meters\")\n",
    "\n",
    "print(\"Pairwise buffer analysis complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, 10 April 2024 1:05:49 PM\",\"Succeeded at Wednesday, 10 April 2024 1:05:49 PM (Elapsed Time: 0.21 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'true'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. erase buffer areas from land, so only on ocean\n",
    "arcpy.analysis.Erase(\"marine_hab_buff250m\", country_polygon, \"marine_hab_buff250m_ocean\", None)\n",
    "\n",
    "#4a. erase reef areas from buffer area - so the buffer areas are only outside of the \n",
    "arcpy.analysis.Erase(\"marine_hab_buff250m_ocean\", \"marine_hab_onepoly\", \"marine_hab_buff250\", None)\n",
    "\n",
    "#4c. delete intermediate files \n",
    "arcpy.management.Delete(\"marine_hab_buff250m_ocean\")\n",
    "arcpy.management.Delete(\"marine_hab_buff250m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#5a. add field for reef poly = 100, \n",
    "\n",
    "#create new field in attribute table called VALUE (to assign value to reef area)\n",
    "arcpy.management.AddField('marine_hab_onepoly',\"Value\", 'SHORT',3,\"\",\"\",\"Value\",\"\",\"\",\"\")\n",
    "\n",
    "#Set reef area value to 100\n",
    "fc = \"marine_hab_onepoly\"\n",
    "field = ['Value']\n",
    "\n",
    "with arcpy.da.UpdateCursor(fc, field) as cursor:\n",
    "\tfor row in cursor:\n",
    "        \tif row[0] == None: \n",
    "            \t\trow[0] = 100\n",
    "            \t\tcursor.updateRow(row) #NOTE INDENTS ARE VERY IMPORTANT\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5a. add field for buff poly = 50, \n",
    "\n",
    "#create new field in attribute table called VALUE (to assign value to reef area)\n",
    "arcpy.management.AddField('marine_hab_buff250',\"Value\", 'SHORT',3,\"\",\"\",\"Value\",\"\",\"\",\"\")\n",
    "\n",
    "#Set reef area value to 100\n",
    "fc = \"marine_hab_buff250\"\n",
    "field = ['Value']\n",
    "\n",
    "with arcpy.da.UpdateCursor(fc, field) as cursor:\n",
    "\tfor row in cursor:\n",
    "        \tif row[0] == None: \n",
    "            \t\trow[0] = 50\n",
    "            \t\tcursor.updateRow(row) #NOTE INDENTS ARE VERY IMPORTANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, 10 April 2024 1:07:46 PM\",\"WARNING 000388: C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\\\\marine_hab_onepoly will lose Zs, since the output is not Z enabled\",\"WARNING 000387: C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\\\\marine_hab_onepoly will lose Ms, since the output is not M enabled\",\"WARNING 000388: C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\\\\marine_hab_buff250 will lose Zs, since the output is not Z enabled\",\"WARNING 000387: C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\\\\marine_hab_buff250 will lose Ms, since the output is not M enabled\",\"Succeeded at Wednesday, 10 April 2024 1:07:52 PM (Elapsed Time: 6.40 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\\\\marine_and_adjacent_hab'>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6. combine reef poly and buff poly\n",
    "#for some reason merge is not working with these layers. must be very very small topology issues that limit data transfer of the value field when merge\n",
    "#instead - make a feature class \n",
    "#then APPEND the two layers together and save into new feature class created\n",
    "#value = 100 is marine habitat (benthic, geomorphic, mangrove)\n",
    "#value = 50 is areas within 250 m of marine habitat\n",
    "\n",
    "arcpy.management.CreateFeatureclass(gdb_workspace, \"marine_and_adjacent_hab\", 'POLYGON', 'marine_hab_buff250',\"\", \"\", project_coord)\n",
    "arcpy.management.Append(\"marine_hab_onepoly;marine_hab_buff250\", \"marine_and_adjacent_hab\", \"TEST\", None, '', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#7. convert reef+adj poly into raster\n",
    "\n",
    "with arcpy.EnvManager(cellSize=\"fish_access_scale\"):\n",
    "    arcpy.conversion.PolygonToRaster(\"marine_and_adjacent_hab\", \"Value\", \"marine_and_adjacent_hab_rast\", \"CELL_CENTER\", \"NONE\", 50, \"BUILD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Time: Thursday, 22 September 2022 12:28:49 PM\n",
    "Succeeded at Thursday, 22 September 2022 2:38:04 PM \n",
    "(Elapsed Time: 2 hours 9 minutes 14 seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <a id= \"combinereeflayers\"></a>\n",
    "\n",
    "## 3c. Combine Reef and Fish Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#combine layers\n",
    "#marine_fishing_areas_raster: Reef Area = 100, 250 buff around reef areas = 50\n",
    "#reef_area_scale: 100-0 scaled values for benthic and geomorphic habitat types\n",
    "\n",
    "out_raster = arcpy.ia.CellStatistics(\"marine_and_adjacent_hab_rast;marine_hab_scale\",\"SUM\", \"DATA\", \"SINGLE_BAND\", 90, \"AUTO_DETECT\");\n",
    "out_raster.save(\"fish_resource_layer\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "#scale final layer\n",
    "#identify min and max values of fishing_resource\n",
    "\n",
    "fish_res_min_output = arcpy.management.GetRasterProperties('fish_resource_layer', 'MINIMUM',\"\") #extracts minimum value from raster\n",
    "fish_res_min = int(fish_res_min_output.getOutput(0)) #assigns that value to an object, and converts to a integer\n",
    "print(fish_res_min)\n",
    "\n",
    "fish_res_max_ouput = arcpy.management.GetRasterProperties('fish_resource_layer', 'MAXIMUM',\"\")\n",
    "fish_res_max = int(fish_res_max_ouput.getOutput(0))\n",
    "print(fish_res_max)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "#checking object type to confirm integer\n",
    "print(type(fish_res_min))\n",
    "print(type(fish_res_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale fishing resource raster from 0 - 100 \n",
    "\n",
    "outraster = ((arcpy.Raster(\"fish_resource_layer\") - fish_res_min)/(fish_res_max - fish_res_min))*100; outraster.save(\"fish_resource_scale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"access\"></a>\n",
    "\n",
    "\n",
    "# 4. Access Layer\n",
    "\n",
    "a. Distance to coast\n",
    "b. population extrapolated to ocean area\n",
    "c. combine distance and ocean pop and scale\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"distcoast\"></a>\n",
    "\n",
    "## 4a. Distance to coast\n",
    "\n",
    "a. create buffer area \n",
    "    - distance = 10 km\n",
    "b. *euclidian distance from coastline*\n",
    "c. scale distance to 0-100. 100 = near coast, 0 = far from coast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, 10 April 2024 1:24:25 PM\",\"Succeeded at Wednesday, 10 April 2024 1:24:51 PM (Elapsed Time: 26.25 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\\\\coast_to_20k'>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a. create a buffer area from coastline to 20km offshore. \n",
    "#just allows to clip,select etc\n",
    "#outside only means doesnt include land area\n",
    "arcpy.analysis.Buffer(country_polygon, \"coast_to_20k\", \"20 Kilometers\", \"OUTSIDE_ONLY\", \"ROUND\", \"ALL\", None, \"PLANAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(offshore_access_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#b. create distance measure raster from coast\n",
    "#distance is 10 km\n",
    "\n",
    "# distance called offshore_access_10k (10000 is default )\n",
    "out_distance_raster = arcpy.sa.EucDistance(country_line, offshore_access_distance, 50, None, \"PLANAR\", None, None); out_distance_raster.save(os.path.join(gdb_workspace, 'Dist_Coast_10k'))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, 10 April 2024 1:30:52 PM\",\"Succeeded at Wednesday, 10 April 2024 1:30:53 PM (Elapsed Time: 0.35 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'true'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clip raster distance layer to only offshore areas \n",
    "#bc the distance measures either side of the country line (i.e. ocean and land)\n",
    "out_raster = arcpy.sa.ExtractByMask(\"Dist_Coast_10k\", \"coast_to_20k\", \"INSIDE\"); out_raster.save(\"Dist_offshore_10k\")\n",
    "\n",
    "#delete intermediate raster\n",
    "arcpy.management.Delete(\"Dist_Coast_10k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "#c. scale distance from coast\n",
    "\n",
    "#identify min and max values of distance from coast\n",
    "\n",
    "coast_dist_min_output = arcpy.management.GetRasterProperties('Dist_offshore_10k', 'MINIMUM',\"\") #extracts minimum value from raster\n",
    "coast_dist_min = int(coast_dist_min_output.getOutput(0)) #assigns that value to an object, and converts to a integer\n",
    "print(coast_dist_min)\n",
    "\n",
    "coast_dist_max_ouput = arcpy.management.GetRasterProperties('Dist_offshore_10k', 'MAXIMUM',\"\")\n",
    "coast_dist_max = int(coast_dist_max_ouput.getOutput(0))\n",
    "print(coast_dist_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "#checking object type to confirm integer\n",
    "print(type(coast_dist_min))\n",
    "print(type(coast_dist_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scale distance raster 0 -100\n",
    "\n",
    "\n",
    "#have to subtract by 100 and take the absolute value so invert the distance from coast, so the high values in the scaled layer are near the coast, and 0 is far from the coast\n",
    "outraster = arcpy.sa.Abs((((arcpy.Raster(\"Dist_offshore_10k\") - coast_dist_min)/(coast_dist_max - coast_dist_min))*100)-100); \n",
    "outraster.save(\"dist_from_coast_scale\")\n",
    "\n",
    "#otherwise you can run this rescale by function, but it does the same thing.\n",
    "#out_raster = arcpy.sa.RescaleByFunction(\"Offshore_Dist_5k\", \"MSSMALL # # # # # #\", 100, 0); out_raster.save(\"dist_coast_rescalefxn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, 10 April 2024 1:46:45 PM\",\"Succeeded at Wednesday, 10 April 2024 1:46:46 PM (Elapsed Time: 0.41 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'true'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine distance raster with blank raster to get full coverage across all solomons\n",
    "\n",
    "out_raster = arcpy.ia.CellStatistics(\"blank_rast_ocean;dist_from_coast_scale\",\"SUM\", \"DATA\", \"SINGLE_BAND\", 90, \"AUTO_DETECT\");\n",
    "out_raster.save(\"dist_from_coast_scale_SI\")\n",
    "\n",
    "#delete intermediate layer\n",
    "arcpy.management.Delete(\"dist_from_coast_scale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"popcoast\"></a>\n",
    "\n",
    "## 4b. Population est to coast\n",
    "\n",
    "a. summarise  raster values to enumeration area suburb polygon data. zonal statistics as table  \n",
    "b. join sum zone table to suburb layer  \n",
    "c. extrapolate total pop counts to coastal areas. \n",
    "d. clip pop extrapolation raster to 5k from shore\n",
    "e. scale extrapolated population raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, 10 April 2024 1:47:15 PM\",\"Value raster being used as snap raster; this is new default behavior.\",\"WARNING 010566: Some zones may not have been rasterized.\",\"Succeeded at Wednesday, 10 April 2024 1:47:17 PM (Elapsed Time: 2.69 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<geoprocessing server result object at 0x212f06e9570>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a. summarise raster population data to enumeration areas (suburb) layer and output as a table.\n",
    "arcpy.ia.ZonalStatisticsAsTable(Suburb, \"EAID\", \"pop_count_SI\", \"EnumArea_totalpop_table\", \"DATA\", \"SUM\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SB_2009_EnumArea_4326_shp\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#arcpy.management.Delete('Suburb_pop')\n",
    "print(Suburb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, 10 April 2024 2:34:22 PM\",\"Succeeded at Wednesday, 10 April 2024 2:34:22 PM (Elapsed Time: 0.02 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'Suburb_pop_Layer7'>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b. create new suburb layer so we can keep original unedited\n",
    "#arcpy.management.CopyFeatures(Suburb, \"Suburb_pop\")\n",
    "\n",
    "#join table of summed pop to suburb layer\n",
    "arcpy.management.AddJoin(\n",
    "    in_layer_or_view=\"Suburb_pop\",\n",
    "    in_field=\"EAID\",\n",
    "    join_table=\"EnumArea_totalpop_table\",\n",
    "    join_field=\"EAID\",\n",
    "    join_type=\"KEEP_ALL\",\n",
    "    index_join_fields=\"INDEX_JOIN_FIELDS\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a summarise raster zone layer\n",
    "out_raster = arcpy.ia.ZonalStatistics(Suburb, \"EAID\", \"pop_count_SI\", \"SUM\", \"DATA\", \"CURRENT_SLICE\", 90, \"AUTO_DETECT\", \"ARITHMETIC\", 360); \n",
    "out_raster.save(\"suburb_zonalstats_pop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, 10 April 2024 2:29:26 PM\",\"Adding Pop_Sum to Suburb_pop...\",\"Succeeded at Wednesday, 10 April 2024 2:29:26 PM (Elapsed Time: 0.15 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\\\\Suburb_pop'>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add new field in attribute table to rename field and make as integer\n",
    "arcpy.management.AddField('Suburb_pop', \"Pop_Sum\", \"SHORT\")\n",
    "\n",
    "#copy to new field as save as integer\n",
    "#field is called \"Suburb_pop.Pop_Sum\" because of the way the add join combined fields in a layer\n",
    "#arcpy.management.CalculateField('Suburb_pop', 'Suburb_pop.Pop_Sum', '!EnumArea_totalpop_table.SUM!', 'PYTHON3','', 'SHORT')\n",
    "\n",
    "\n",
    "#NOTE SOMETHING WEIRD HAPPENING HERE! need to go back through this code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#c. extrapolate total pop to ocean areas using euclidian distance\n",
    "#parameters:\n",
    "    # max distance = 5000 m\n",
    "    # cell size = the same as the blank rast ocean (50m)\n",
    "    # allocation value = summed population count for each suburb/enumeration area\n",
    "with arcpy.EnvManager(cellSize=\"blank_rast_ocean\"):\n",
    "    out_distance_allocation_raster = arcpy.sa.DistanceAllocation(\"Suburb_pop\", None, None, None, None, \"BINARY 1 -30 30\", None, \"BINARY 1 45\", None, None, None, None, \"Pop_Sum\", None, None, None, '', \"PLANAR\"); \n",
    "    out_distance_allocation_raster.save(\"Ocean_allocation_pop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, 10 April 2024 2:40:20 PM\",\"Succeeded at Wednesday, 10 April 2024 2:40:49 PM (Elapsed Time: 29.26 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\\\\coast_buff_10k'>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#d. clip extrapolation raster (ocean allocation) to 10km coastline buffer\n",
    "\n",
    "#must create 5k coast buffer  first. \n",
    "arcpy.analysis.Buffer(country_polygon, \"coast_buff_10k\", \"10 Kilometers\", \"OUTSIDE_ONLY\", \"ROUND\", \"ALL\", None, \"PLANAR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract by mask (clip) raster data into 5k buff area\n",
    "out_raster = arcpy.sa.ExtractByMask(\"Ocean_allocation_pop\", \"coast_buff_10k\", \"INSIDE\"); out_raster.save(\"ocean_pop_10k\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "2748\n"
     ]
    }
   ],
   "source": [
    "#e. scale distance from coast\n",
    "\n",
    "#identify min and max values of ocean pop allocation layer\n",
    "\n",
    "ocean_pop_min_output = arcpy.management.GetRasterProperties('ocean_pop_10k', 'MINIMUM',\"\") #extracts minimum value from raster\n",
    "ocean_pop_min = int(ocean_pop_min_output.getOutput(0)) #assigns that value to an object, and converts to a integer\n",
    "print(ocean_pop_min)\n",
    "\n",
    "ocean_pop_max_ouput = arcpy.management.GetRasterProperties('ocean_pop_10k', 'MAXIMUM',\"\")\n",
    "ocean_pop_max = int(ocean_pop_max_ouput.getOutput(0))\n",
    "print(ocean_pop_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#e. scale ocean population raster\n",
    "\n",
    "outraster = ((arcpy.Raster(\"ocean_pop_10k\") - ocean_pop_min)/(ocean_pop_max - ocean_pop_min))*100; outraster.save(\"ocean_pop_10k_scale\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, 10 April 2024 2:56:38 PM\",\"Succeeded at Wednesday, 10 April 2024 2:56:38 PM (Elapsed Time: 0.14 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'true'>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#delete intermediate layers\n",
    "arcpy.management.Delete(\"Ocean_allocation_pop\")\n",
    "arcpy.management.Delete(\"EnumArea_totalpop_table\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"dist_city\"></a>\n",
    "\n",
    "## 4c. Distance to Major Cities  - Gravity\n",
    "\n",
    "Im going to attempt the gravity function. or a version of it  \n",
    "\n",
    "Cinner does it for many reef site locations  \n",
    "    - by clipping populations cells within 500 km of reef sites  \n",
    "    - measure least cost path using some R function of land cover to measure least cost distance between two cells   \n",
    "    - dist measures from every populated cell on land to centroid of nearest reef site  (Dist from cell to reef point)  \n",
    "    - gravity is then measured as:  \n",
    "            - pop of cell / (travel time between reef site and that cell)^2  \n",
    "            - summed the gravity values for every cell within 500 km of reef sites to get total gravity for a reef area  \n",
    "  \n",
    "  \n",
    "Im going to:  \n",
    "    - measure the distance from reef cell to population point (market/city locations)\n",
    "    - from the city center point (cell) outwards by distance.  \n",
    "    - weight the travel time by the nearest city population. \n",
    "    - using the tool: \" tbd \"\n",
    "      \n",
    "  \n",
    "we already have:  \n",
    "    - euclidian distance from coast - linear decay  \n",
    "    - population of coastal municipality projected into water areas  \n",
    "    - those combined give the scaled allocation of population onto marine areas   \n",
    "            - I am posing that this is an estimate of SUBSISTENCE fishing.   \n",
    "    - \n",
    "what the distance to market would add  (travel time weighted by population of city)  \n",
    "    - is some measure of more commercialised (but not that word) fishing where markets would draw extra fishing effort.   \n",
    "    - we are not using it as a FISH BIOMASS estimator like what cinner was doing  \n",
    "    - we are using it as a pressure indicator. kind of the inverse of what cinner et al did.  \n",
    "    - still want to make a least cost path informed by cinners travel time estimates:  \n",
    "    - Need to add road to raster layer  \n",
    "  \n",
    "| ESA Land Cover Layer   | Value   | Speed (km/h) |  Time (min/km) |\n",
    "|    :---                |  :---   | :---         |  :---          |\n",
    "|Tree Cover              |  10     |    1     |   60    | \n",
    "|Shrubland               |  20     |    1.6   |   37.5  |\n",
    "|Grassland               |  30     |    1.6   |   37.5  |\n",
    "|Cropland                |  40     |    1.6   |   37.5  |\n",
    "|Built Up                |  50     |    30    |   2     |\n",
    "|Bare/Sparse Vegetation  |  60     |    1.25  |   48    |\n",
    "|Snow and Ice            |  70     |    1     |   60    |\n",
    "|Permanent Water Bodies  |  80     |    20    |   3     |\n",
    "|Herbaceous Wetland      |  90     |    1     |   60    |\n",
    "|Mangrove                |  95     |    1     |   60    |\n",
    "|Road                    |  100    |    60    |   1     |\n",
    "*road gets added to raster layer  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps: \n",
    "1. convert road to raster layer (same resolution as ESA)\n",
    "    - road value = 100\n",
    "2. merge road rater and ESA layer together where road takes precedence over ESA layer\n",
    "3. reclassify esa and road raster layer to above classifications for *TIME* - so faster travel = lower cost\n",
    "4. calcuate least cost path distance. \n",
    "5. or gravity = meaning travel time from each market area (within each cell) (pop of market city/(cell value of tt)^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field 'Value' added to the attribute table and all values now 100\n"
     ]
    }
   ],
   "source": [
    "#1. convert road to raster\n",
    "\n",
    "#1a. add field to attribute table and assign value of 100\n",
    "\n",
    "arcpy.env.workspace = gdb_workspace\n",
    "\n",
    "roads = \"osm_SI_roads_p_shp\"\n",
    "\n",
    "new_field = \"Value\"\n",
    "\n",
    "#add new field to attribute table\n",
    "arcpy.AddField_management(roads, new_field, \"SHORT\")\n",
    "\n",
    "with arcpy.da.UpdateCursor(roads, new_field) as cursor:\n",
    "    for row in cursor:\n",
    "        row[0] = 100\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(\"Field '{}' added to the attribute table and all values now 100\". format(new_field))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.30599049986377\n",
      "Line feature converted to raster successfully using the cell size of the reference raster.\n"
     ]
    }
   ],
   "source": [
    "#1b convert to raster\n",
    "roads = \"osm_SI_roads_p_shp\"\n",
    "\n",
    "output_raster = \"road_rast\"\n",
    "\n",
    "field = \"Value\"\n",
    "\n",
    "#cell size reference to the ESA layer so they match resolution\n",
    "esa_raster = r\"C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Forest_ExPot.gdb/esa2020_si\"\n",
    "\n",
    "#Obtain the cell size of the reference raster\n",
    "cell_size = arcpy.GetRasterProperties_management(esa_raster, \"CELLSIZEX\").getOutput(0)\n",
    "print(cell_size)\n",
    "\n",
    "#convert line feature to raster using cell size of reference raster\n",
    "arcpy.conversion.PolylineToRaster(roads, field, output_raster, \"MAXIMUM_LENGTH\", \"\", cell_size)\n",
    "\n",
    "print(\"Line feature converted to raster successfully using the cell size of the reference raster.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\n"
     ]
    }
   ],
   "source": [
    "print(arcpy.env.workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raster saved to: C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Fishing_ExPot.gdb\\esa_and_road\n"
     ]
    }
   ],
   "source": [
    "#2. merge road and ESA rasters\n",
    "\n",
    "#overwrite existing outputs \n",
    "#arcpy.env.overwriteOutput = True\n",
    "#want to combined the two rasters - esa and roads\n",
    "\n",
    "esa_raster = r\"C:/Users/jc446202/OneDrive - James Cook University (1)/ACIAR_spatial/modified_dat/Forest_ExPot.gdb/esa2020_si\"\n",
    "road_raster = \"road_rast\"\n",
    "\n",
    "# Perform the mosaic operation\n",
    "output_raster = arcpy.management.MosaicToNewRaster(\n",
    "    input_rasters=[road_raster, esa_raster],\n",
    "    output_location=gdb_workspace,\n",
    "    raster_dataset_name_with_extension=\"esa_and_road\",\n",
    "    coordinate_system_for_the_raster=None,\n",
    "    pixel_type=\"8_BIT_UNSIGNED\",\n",
    "    cellsize=None,\n",
    "    number_of_bands=1,\n",
    "    mosaic_method=\"MAXIMUM\",\n",
    "    mosaic_colormap_mode=\"MATCH\"\n",
    ")\n",
    "\n",
    "# Print the full path of the saved raster dataset\n",
    "print(\"Raster saved to:\", output_raster)\n",
    "\n",
    "# I have no idea why, but instead of the road getting added to the esa layer as 100, it gets added as 18??\n",
    "# *BE AWARE ROAD = 18 in new mosaic raster*\n",
    "\n",
    "#note - if you get an error, you need to run checkoutextension. this is if you have a concurrent license  \n",
    "#if you need to rerun this, need to delete the previous bc mosaic cannot overwrite existing object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, 11 April 2024 10:10:39 AM\",\"Succeeded at Thursday, 11 April 2024 10:10:39 AM (Elapsed Time: 0.45 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'true'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(output_raster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Add blank ocean raster to fill the ocean space that ESA doesnt cover\n",
    "\n",
    "full_raster_output = os.path.join(gdb_workspace, \"esa_w_road_full_extent\")\n",
    "\n",
    "\n",
    "with arcpy.EnvManager(extent=\"MAXOF\"):\n",
    "    out_raster = arcpy.ia.Con(\n",
    "        in_conditional_raster=\"esa_and_road\",\n",
    "        in_true_raster_or_constant=\"esa_and_road\",\n",
    "        in_false_raster_or_constant=\"blank_rast_ocean\",\n",
    "        where_clause=\"Value IS NOT NULL\"\n",
    "    )\n",
    "out_raster.save(full_raster_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reclassification complete\n"
     ]
    }
   ],
   "source": [
    "#3. reclassify esa + road raster to travel time\n",
    "#need to multiple the values by ten because the raster needs to be an integer\n",
    "\n",
    "remap = arcpy.sa.RemapValue([ #reclassifies land use to travel time (min per km)\n",
    "    [ 0, 3],     #reclassify 0 to 3 (ocean)\n",
    "    [10, 60],    # reclassify 10 to 60 (tree cover)\n",
    "    [18, 1],     # reclassify 18 to 1 (road)\n",
    "    [20, 38],    # reclassify 20 to 37.5 (shrubland)\n",
    "    [30, 38],    # reclassify 30 to 37.5 (grassland)\n",
    "    [40, 38],    # reclassify 40 to 37.5 (cropland)\n",
    "    [50, 2],     # reclassify 50 to 2 (built up)\n",
    "    [60, 48],    # reclassify 60 to 48 (bare/sparse veg)\n",
    "    [70, 60],    # reclassify 70 to 60 (snow and ice)\n",
    "    [80, 3],     # reclassify 80 to 3 (permanent water)\n",
    "    [90, 60],    # reclassify 90 to 60 (herbaceous wetland)\n",
    "    [95, 60],    # reclassify 95 to 60 (mangrove)\n",
    "    [100, 1],    # reclassify 100 to 1 (road)\n",
    "])\n",
    "\n",
    "    \n",
    " #run spatial analyst tool and operation to check if it runs\n",
    "output_raster = \"esa_w_road_travel_cost\"\n",
    "    \n",
    "#perform reclassification\n",
    "reclass_raster = arcpy.sa.Reclassify(\"esa_w_road_full_extent\", \"Value\", remap)\n",
    "reclass_raster.save(output_raster)\n",
    "print(\"reclassification complete\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. calculate least cost path\n",
    "\n",
    "\n",
    "# Define input data\n",
    "output_raster = os.path.join(gdb_workspace, \"travel_dist_cost\")\n",
    "accumulation_type = \"LINEAR\"  # Other options: CONSTANT, EQUAL\n",
    "\n",
    "  \n",
    "        \n",
    "# Use CostDistance tool with appropriate parameters\n",
    "#out_distance_accumulation_raster = arcpy.sa.DistanceAccumulation(  #commenting this out because it takes hours to run\n",
    "    in_source_data=\"SI_Cities\",\n",
    "    in_barrier_data=None,\n",
    "    in_surface_raster=None,\n",
    "    in_cost_raster=\"esa_w_road_travel_cost\",\n",
    "    in_vertical_raster=None,\n",
    "    vertical_factor=\"BINARY 1 -30 30\",\n",
    "    in_horizontal_raster=None,\n",
    "    horizontal_factor=\"BINARY 1 45\",\n",
    "    out_back_direction_raster=None,\n",
    "    out_source_direction_raster=None,\n",
    "    out_source_location_raster=None,\n",
    "    source_initial_accumulation=None,\n",
    "    source_maximum_accumulation=None,\n",
    "    source_cost_multiplier=None,\n",
    "    source_direction=\"\",\n",
    "    distance_method=\"PLANAR\"\n",
    ")\n",
    "out_distance_accumulation_raster.save(output_raster)\n",
    "    \n",
    "  \n",
    "print(f\"Distance raster with cost and population weight saved to {output_raster}.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before we scale we want to clip the cost raster so its just around the islands, \n",
    "#because really were interested in the cost associated with travel between island to reach larger cities, not way out on the edge of the EEZ which really alters the scaled values\n",
    "\n",
    "arcpy.analysis.Buffer(country_polygon, \"Sols_buff200k\", \n",
    "    buffer_distance_or_field=\"200 Kilometers\",\n",
    "    line_side=\"FULL\",\n",
    "    line_end_type=\"ROUND\",\n",
    "    dissolve_option=\"ALL\",\n",
    "    dissolve_field=None,\n",
    "    method=\"PLANAR\"\n",
    ")\n",
    "\n",
    "#and make buffer areas just over water areas, remove land\n",
    "arcpy.analysis.Erase(\n",
    "    in_features=\"Sols_buff200k\",\n",
    "    erase_features= country_polygon,\n",
    "    out_feature_class=\"Sols_buff_200km_noland\",\n",
    "    cluster_tolerance=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clip the travel cost raster to the 200 km buffer\n",
    "#want land included here, bc presuming distance crossed along land\n",
    "\n",
    "out_raster = arcpy.sa.ExtractByMask(\n",
    "    in_raster=\"travel_dist_cost\",\n",
    "    in_mask_data=\"Sols_buff200k\",\n",
    "    extraction_area=\"INSIDE\"\n",
    ")\n",
    "out_raster.save(\"travel_dist_cost_200kmbuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale values 0-100 where near to cities is highest value (greatest potential impact)\n",
    "\n",
    "out_raster = arcpy.sa.RescaleByFunction(\n",
    "    in_raster=\"travel_dist_cost_200kmbuff\",\n",
    "    transformation_function=\"LINEAR # # # # # #\",\n",
    "    from_scale=100, #this is inverting the rescale so the higher values (100) are acutally closer to the cities.\n",
    "    to_scale=1\n",
    ")\n",
    "out_raster.save(\"travel_dist_cost_scale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract by mask so its only in water areas. \n",
    "\n",
    "out_raster = arcpy.sa.ExtractByMask(\n",
    "    in_raster=\"travel_cost_cities_scale\",\n",
    "    in_mask_data=\"Sols_buff_200km_noland\",\n",
    "    extraction_area=\"INSIDE\"\n",
    ")\n",
    "out_raster.save(\"travel_dist_cost_scale_noland\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, 15 April 2024 11:41:13 AM\",\"Succeeded at Monday, 15 April 2024 11:41:13 AM (Elapsed Time: 0.63 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'true'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#delete intermediate layers\n",
    "\n",
    "arcpy.management.Delete(\"travel_dist_cost_200kmbuff\")\n",
    "arcpy.management.Delete(\"esa_w_road_travel_cost\")\n",
    "arcpy.management.Delete('esa_w_road_full')\n",
    "arcpy.management.Delete('road_rast')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"combineaccess\"></a>\n",
    "\n",
    "## 4d. combine access layers and scale\n",
    "\n",
    "combining dist_from_coast_scale_full + ocean_pop_5k_scale + travel_dist_cost_scale_no_land\n",
    "rescaling combined raster\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out_raster = arcpy.ia.CellStatistics(\"dist_from_coast_scale_SI;ocean_pop_10k_scale;travel_dist_cost_scale_noland\",\"SUM\", \"DATA\", \"SINGLE_BAND\", 90, \"AUTO_DETECT\");\n",
    "out_raster.save(\"fish_access_layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "298.452209472656\n"
     ]
    }
   ],
   "source": [
    "#scale access layer\n",
    "\n",
    "\n",
    "#identify min and max values of access layer\n",
    "\n",
    "access_min_output = arcpy.management.GetRasterProperties('fish_access_layer', 'MINIMUM',\"\") #extracts minimum value from raster\n",
    "access_min = float(access_min_output.getOutput(0)) #assigns that value to an object, and converts to a integer\n",
    "print(access_min)\n",
    "\n",
    "access_max_ouput = arcpy.management.GetRasterProperties('fish_access_layer', 'MAXIMUM',\"\")\n",
    "access_max = float(access_max_ouput.getOutput(0))\n",
    "print(access_max)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outraster = ((arcpy.Raster(\"fish_access_layer\") - access_min)/(access_max - access_min))*100; outraster.save(\"fish_access_scale\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= \"impact\"></a>\n",
    "\n",
    "\n",
    "# 7. Combine access, and resource layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine resource and access layers\n",
    "\n",
    "out_raster = arcpy.ia.CellStatistics(\"fish_resource_scale;fish_access_scale\",\"SUM\", \"DATA\", \"SINGLE_BAND\", 90, \"AUTO_DETECT\");\n",
    "out_raster.save(\"fish_ExPot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "187.440643310547\n"
     ]
    }
   ],
   "source": [
    "#scale fish impact layer\n",
    "\n",
    "#identify min and max values of access layer\n",
    "\n",
    "fish_impact_min_output = arcpy.management.GetRasterProperties('fish_ExPot', 'MINIMUM',\"\") #extracts minimum value from raster\n",
    "fish_impact_min = int(fish_impact_min_output.getOutput(0)) #assigns that value to an object, and converts to a integer\n",
    "print(fish_impact_min)\n",
    "\n",
    "fish_impact_max_ouput = arcpy.management.GetRasterProperties('fish_ExPot', 'MAXIMUM',\"\")\n",
    "fish_impact_max = float(fish_impact_max_ouput.getOutput(0))\n",
    "print(fish_impact_max)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale fishing impact layer\n",
    "outraster = ((arcpy.Raster(\"fish_ExPot\") - fish_impact_min)/(fish_impact_max - fish_impact_min))*100; outraster.save(\"fish_ExPot_scale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CheckedIn'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.CheckInExtension(\"Spatial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TemplateNotFound",
     "evalue": "report-template.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTemplateNotFound\u001b[0m                          Traceback (most recent call last)",
      "In  \u001b[0;34m[1]\u001b[0m:\nLine \u001b[0;34m3\u001b[0m:     template = env.get_template(\u001b[33m\"\u001b[39;49;00m\u001b[33mreport-template.html\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\jinja2\\environment.py\u001b[0m, in \u001b[0;32mget_template\u001b[0m:\nLine \u001b[0;34m997\u001b[0m:   \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m._load_template(name, \u001b[36mglobals\u001b[39;49;00m)\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\jinja2\\environment.py\u001b[0m, in \u001b[0;32m_load_template\u001b[0m:\nLine \u001b[0;34m958\u001b[0m:   template = \u001b[36mself\u001b[39;49;00m.loader.load(\u001b[36mself\u001b[39;49;00m, name, \u001b[36mself\u001b[39;49;00m.make_globals(\u001b[36mglobals\u001b[39;49;00m))\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\jinja2\\loaders.py\u001b[0m, in \u001b[0;32mload\u001b[0m:\nLine \u001b[0;34m125\u001b[0m:   source, filename, uptodate = \u001b[36mself\u001b[39;49;00m.get_source(environment, name)\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\jinja2\\loaders.py\u001b[0m, in \u001b[0;32mget_source\u001b[0m:\nLine \u001b[0;34m214\u001b[0m:   \u001b[34mraise\u001b[39;49;00m TemplateNotFound(template)\n",
      "\u001b[0;31mTemplateNotFound\u001b[0m: report-template.html\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "from jinja2 import Environment, FileSystemLoader\n",
    "env = Environment(loader=FileSystemLoader('.'))\n",
    "template = env.get_template(\"report-template.html\")\n",
    "template_variables = {\n",
    "    \"title\": item.title,\n",
    "    \"statistics\": [s.attributes for s in statistics],\n",
    "    \"features\": trees}\n",
    "generated_html = template.render(template_variables)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
